{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NYU-IEP-2022-2023-Assignments/LabAnalysis3/blob/main/LabAnalysis3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBFO6nTSr9p1"
      },
      "source": [
        "As in other assignments, this first code block is meant to set things up. **Below, modify the ```!git clone``` line so that the url points to your own data repository.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rl2JqjsMqXUV"
      },
      "source": [
        "# necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os, glob\n",
        "import scipy.optimize\n",
        "import itertools,operator\n",
        "import copy\n",
        "from sklearn.utils import Bunch\n",
        "\n",
        "# MODIFY THIS LINE SO THAT THE URL POINTS TO YOUR DATA REPOSITORY\n",
        "!git clone https://github.com/NYU-IEP-2022-3-Classroom/lab3-data-repository-mgershow\n",
        "\n",
        "#this line makes sure you followed the direction above; if you see 20 copies of \"you didn't change the directory to match your name!\" that means you need to update the data repository name and clone again\n",
        "#delete my data repository (use folder icon on the left) or you will get this message again\n",
        "if os.path.isdir('lab3-data-repository-mgershow'):\n",
        "  for i in range(20):\n",
        "    print (\"You didn't change the directory to match your name!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9-yrTRqwKBW"
      },
      "source": [
        "These functions are needed to load the data and do a little pre-processing. Run the cell, but you don't need to change anything"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def findAngleFiles (startdir):\n",
        "  #angleFiles = findAngleFiles(startdir)\n",
        "  # input stardir: path to top level directory (e.g. data_repository/large bob)\n",
        "  # output angleFiles: array with paths to angle files  \n",
        "  #https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python\n",
        "  #https://www.kite.com/python/answers/how-to-search-for-specific-files-in-subdirectories-in-python\n",
        "\n",
        "  angleFiles = sorted(glob.glob(startdir + '/**/*_angle.txt'))\n",
        "  return (angleFiles)\n",
        "\n",
        "# fitting an exponential\n",
        "# exponential has two parameters, the y-intercept (a) and the\n",
        "# exponential multiplier constant (b which for our purposes is -1/tau)\n",
        "# uses cauchy loss function to reduce the influence of outliers\n",
        "# inputs: x,y - numpy arrays\n",
        "# outputs: a: fit value of y(0)\n",
        "#          b: fit value of exonent\n",
        "#          fity: a * e^(bx) \n",
        "def fitExponentialCauchyLoss(x,y):\n",
        "  xx = x - np.min(x)\n",
        "  yy = y / np.max(y)\n",
        "  res = scipy.optimize.least_squares(lambda p : p[0]*np.exp(p[1] * xx)-yy,  (1, -1/max(xx)), loss = 'cauchy')\n",
        "  a = res.x[0]\n",
        "  b = res.x[1]\n",
        "  a = a*np.max(y)*np.exp(-b*np.min(x))\n",
        "  return (a,b, a*np.exp(b*x))\n",
        "\n",
        "\n",
        "\n",
        "# load angle file and do some minor processing\n",
        "# inputs: filepath - path of the file\n",
        "# outputs: bunch object with fields\n",
        "# number crossing number since start of experiment (a full period is 2 crossings)\n",
        "# time time of crossing since start of experiment (resolution = 1us, accuracy unknown)\n",
        "# majaxis major axis (in mm) from fitter\n",
        "# minaxis minor axis (in mm) from fitter\n",
        "# theta angle of major axis (in radians) relative to x-axis, from fitter\n",
        "# slope slope of the voltage vs. time trace (in V/s) at time of crossing --  proportional to the total energy of the bob\n",
        "# dnamplitude denoised amplitude (```sqrt(majaxis**2 + minaxis**2)```) (in mm)  found by fitting the amplitude to a decaying exponential using a cost-function that discards outliers\n",
        "# dnmajaxis denoised major axis (see fit amplitude) (in mm)\n",
        "# dnslope denoised slope (in V/s)\n",
        "# filename name of the file the experiment was loaded from\n",
        "\n",
        "def loadAngleFile(filepath, maxTime = 10000000):\n",
        "  number, time, majaxis, minaxis, theta, slope = np.loadtxt(filepath, skiprows = 1, unpack = True)\n",
        "  _,_,fitamplitude = fitExponentialCauchyLoss(time-time[0],np.sqrt(minaxis**2 + majaxis**2))\n",
        "  _,_,fitmajaxis = fitExponentialCauchyLoss(time-time[0],majaxis)\n",
        "  _,_,fitslope = fitExponentialCauchyLoss(time-time[0],slope)\n",
        "  \n",
        "  return(Bunch(number=number-number[0],time=time-time[0],majaxis=majaxis,dnamplitude=fitamplitude,minaxis=minaxis,theta=theta,slope=slope,dnmajaxis=fitmajaxis, dnslope=fitslope,filename=filepath))\n",
        "  \n",
        "def trimExperiment(oldexpt, timerange):\n",
        "  expt = copy.copy(oldexpt)\n",
        "  valid = np.logical_and(expt.time >= np.min(timerange), expt.time <= np.max(timerange))\n",
        "  expt.time = expt.time[valid]\n",
        "  expt.time = expt.time - expt.time[0]\n",
        "  expt.number = expt.number[valid]\n",
        "  expt.number = expt.number - expt.number[0]\n",
        "  expt.majaxis = expt.majaxis[valid]\n",
        "  expt.minaxis = expt.minaxis[valid]\n",
        "  expt.theta = expt.theta[valid]\n",
        "  expt.slope = expt.slope[valid] \n",
        "  _,_,expt.dnamplitude = fitExponentialCauchyLoss(expt.time,np.sqrt(expt.minaxis**2 + expt.majaxis**2))\n",
        "  _,_,expt.dnmajaxis = fitExponentialCauchyLoss(expt.time,expt.majaxis)\n",
        "  _,_,expt.dnslope = fitExponentialCauchyLoss(expt.time,expt.slope)\n",
        "  return expt\n"
      ],
      "metadata": {
        "id": "o4585A1ECwTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Analyze the data you collected using the crossing counter panel\n",
        "1. Below, enter the rms amplitude and the period for each measurement. Note that if you made measurements on multiple days, *you cannot simply combine them.* Repeat the analysis for both days separately\n",
        "1. Calcualte the length of your pendulum using $L = g*(T/(2 \\pi))^2$ and g = 9802 mm/s$^2$ so that \n",
        "1. Make a scatter plot of the period vs. $(a/L)^2$ \n",
        "1. Use ```np.polyfit(___,___,1)``` to fit the period to a line of the form $T = T_0 + m (a/L)^2$ and plot the result on the same axes. If you write `p = np.polyfit...)`, then `p[0]` is m and `p[1]` is T\n",
        "1. According to our model, $T_0/m$ should equal 16. Print your result for this value."
      ],
      "metadata": {
        "id": "bt1RQa7xV9VI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#enter the amplitude and periods in the same order, so that period[0] is the period of the measurement with amp[0], period[1] is the period of the measurement with amp[1] etc\n",
        "amp = [] #you fill in this list\n",
        "period = [] #you fill in this list \n",
        "\n",
        "L = #you complete this line\n",
        "\n",
        "# make a plot of period (y-axis) vs. (a/L)^2 (x-axis). Hint: store (a/L)^2 in a variable - you'll use it later\n",
        "#YOUR CODE HERE\n",
        "\n",
        "#fit a line period = T_0 + m * (a/L)^2 using np.polyfit\n",
        "#YOUR CODE HERE\n",
        "\n",
        "#plot the fit line on top of the data\n",
        "#YOUR CODE HERE\n",
        "\n",
        "#print T_0/m\n",
        "\n"
      ],
      "metadata": {
        "id": "PUd1ZXch6KCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**load the data from disk**\n",
        "\n",
        "below is code to load the data from a set of experiments (or just one). you provide the name of the directory that contains all the timestamped directories and it does the rest. \n",
        "\n",
        "You should be able to understand all the code below\n",
        "\n",
        "**edit the first line below**"
      ],
      "metadata": {
        "id": "ys54OEaH3Ck7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##CHANGE LINE BELOW##\n",
        "startdir = 'lab3-data-repository-mgershow/data for analysis/' #change to your data directory (folder containing date stamped folders)\n",
        "\n",
        "angleFiles = findAngleFiles(startdir)\n",
        "print('found {} data files'.format(len(angleFiles)))\n",
        "expt = [loadAngleFile(af) for af in angleFiles]\n",
        "print('loaded {} data files'.format(len(angleFiles)))\n"
      ],
      "metadata": {
        "id": "tMJ5eKG9Cxlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the data is loaded, it will be stored in a list of \"bunch objects\" called expt. You can access the data this way:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "expt[0].time #time of each crossing for the first experiment minus the original time\n",
        "expt[0].fitamplitude #denoised amplitude for each crossing, for the first experiment\n",
        "expt[1].filename #the filename of the second experiment etc.\n",
        "```\n",
        "\n",
        "The valid fields you can find use are\n",
        "\n",
        "1. ```number``` crossing number since start of experiment (a full period is 2 crossings)\n",
        "1. ```time``` time of crossing since start of experiment (resolution = 1us, accuracy unknown)\n",
        "1. ```majaxis``` major axis (in mm) from fitter\n",
        "1. ```minaxis``` minor axis (in mm) from fitter\n",
        "1. ```theta``` angle of major axis (in radians) relative to x-axis, from fitter\n",
        "1. ```slope``` slope of the voltage vs. time trace (in V/s) at time of crossing --  proportional to the total energy of the bob\n",
        "1. ```dnamplitude``` denoised amplitude (```sqrt(majaxis**2 + minaxis**2)```) (in mm)  found by fitting the amplitude to a decaying exponential using a cost-function that discards outliers\n",
        "1. ```dnmajaxis``` denoised major axis (see fit amplitude) (in mm)\n",
        "1. ```dnslope``` denoised slope (in V/s)\n",
        "1. ```filename``` name of the file the experiment was loaded from"
      ],
      "metadata": {
        "id": "yydbtDaOG2Et"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For one experiment (of your choice), **plot the major axis (from the fitter) vs. time and the denoised major axis vs time** on the same axes.\n",
        "\n",
        "\n",
        "\n",
        "Title the plot with the filename"
      ],
      "metadata": {
        "id": "NuU74mcyLODK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#YOUR CODE HERE"
      ],
      "metadata": {
        "id": "McsXAjzhC4qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```trimExperiment(expt,timerange)``` will trim the experiment to a specific time range you indicate and then refit the data, for instance\n",
        "\n",
        "```newexpt = trimExperiment(expt,(60,660))``` \n",
        "\n",
        "will return a new structure that has only the data from 60 seconds after the start of the experiments to 660 seconds after the start\n",
        "\n",
        "you can use ```trimExperiment``` to clean off any ugly bits at the start or end of the experiment if you need to. \n",
        "\n",
        "Use ```trimExperiment``` to create a new experiment structure (```newexpt```) containing the middle 10 minutes (from 300 to 900 seconds) of your chosen experiment (e.g. ```expt[0]```), and plot the major axis and denoised major axis vs. time as before "
      ],
      "metadata": {
        "id": "GU70-24dRY13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#YOUR CODE HERE"
      ],
      "metadata": {
        "id": "5SutzijDS3yG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#OK here is where you start doing all the work!\n",
        "\n",
        "```np.gradient``` estimates the derivative of a function using second order accurate differences\n",
        "\n",
        "$g_i = 0.5 * (f_{i + 1} - f_{i-1})$\n",
        "\n",
        "except at the boundaries\n",
        "\n",
        "$g_0 = f_1 - f_0$ and $g_{n-1} = g_{n-1} - g_{n-2}$\n",
        "\n",
        "The chief advantage of using ```np.gradient``` over ```np.diff```, which just takes the difference between successive points is that ```np.grad``` returns an array that's the same size as the original array\n",
        "\n",
        "For a dataset of your choice:\n",
        "\n",
        "1. Trim the experiment if you need to in order to remove problematic starts or ends\n",
        "1. Calculate the period by taking the gradient of the crossing time (e.g. ```np.gradient(expt[0].time)```)\n",
        "1. Plot the period vs. time\n",
        "1. If there are outliers (e.g. due to a missed crossing, you get a period of 3 seconds instead of 2 seconds), then remove them as follows:\n",
        "  1. Calculate the median period using ```np.median```\n",
        "  2. Find all the periods within 10 ms of the median value (```valid = np.abs(period - medianperiod) < 0.01```)\n",
        "  3. Create new time, amplitude, and period variables using only the `valid' values\n",
        "    \n",
        "       1. ```time = expt[0].time[valid]```\n",
        "       1. ```dnamplitude = expt[0].dnamplitude[valid]```\n",
        "       1.  etc.\n",
        "  1. Plot the period vs. time for the valid data on a new set of axes \n"
      ],
      "metadata": {
        "id": "QTkqN_zNNBlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your code here"
      ],
      "metadata": {
        "id": "BAUYtUjGJ3MX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the prediction $T = T_0(1 + \\frac{1}{16} \\frac{a^2}{L^2})$\n",
        "\n",
        "If your data had outliers in the periods, then use the dataset with the outliers removed that you calculated above\n",
        "\n",
        "1. Calculate $L$ **in mm** using $g = 9802$ mm/s$^2$ and the median period from your measurements above\n",
        "1. Calculate $a^2/L^2$ using the denoised amplitude (which is also in mm)\n",
        "1. Use ```np.polyfit``` to fit the period to an equation of the form $T = T_0 + m*a^2/L^2$ (note that if you store the result as ```p = np.polyfit(...```, then ```p[0]``` is m and ```p[1]``` is $T_0$.\n",
        "1. According to our model, $T_0/m$ should equal 16. Print your result for this value\n",
        "1. Do a 1 parameter fit to the model prediction $T = T_0(1 + \\frac{1}{16} a^2/L^2)$. \n",
        "  1. Since $\\frac{1}{16} a^2/L^2 \\ll 1$, you can write $T_0 = T(1 - \\frac{1}{16} a^2/L^2)$\n",
        "  1. The average value of $T(1 - \\frac{1}{16} a^2/L^2)$ is therefore the best estimate of $T_0$. \n",
        "  1. Use this best estimate to find the predicted period $T = T_0(1 + \\frac{1}{16} a^2/L^2)$\n",
        "1. Plot the period vs. time, the value of the period from the np.polyfit result vs. time, and the value from the one-parameter fit, on the same axes\n",
        "1. Add a legend to the plot that says \"data,\" \"$T = \\_\\_(1 + {1}/{\\_\\_} \\;\\; a^2/L^2)$,\" and \"model\". Fill in the blanks using your fit results to 3 significant digits.\n",
        "1. On a second figure, plot the residuals (period - your polyfit result) vs. time. ylabel `residuals', xlabel 'time'\n",
        "1. On a third figure, plot $T/T_0 - 1$ vs. $a^2/L^2$ along with the line predicted by your fit result. \n",
        "1. On a fourth figure, plot the residuals vs denoised amplitude. ylabel residuals, xlabel 'amplitude'\n",
        "1. On a fifth figure, make a histogram of the residuals with 100 bins spaced evenly from -4 sigma to 4 sigma. Title it with the standard deviation (in mm, to 2 decimal places) of the residuals. \n",
        "1. Calculate a gaussian distribution at the location of the histogram bins using the mean (shoule be 0) and standard deviation of the residuals. Scale this distribution so that its sum is the same as the number of residuals. Plot this gaussian vs. the bins on the same axes as the histogram"
      ],
      "metadata": {
        "id": "fhV76xTFWQ_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#YOUR CODE HERE"
      ],
      "metadata": {
        "id": "YDMAWLpWCjh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you have more than one data set, you can do them all without too much extra work,\n",
        "\n",
        "```\n",
        "for e in expt:\n",
        "  #all the code you wrote before, just change expt[0] to e\n",
        "  plt.show()\n",
        "  ```\n"
      ],
      "metadata": {
        "id": "xag0FqeJiKhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#QUESTIONS\n",
        "\n",
        "1. To what extent are your data consistent/inconsistent with the simulation you did last week? How does your fit to the data agree with/differ from the one-parameter model fit?\n",
        "\n",
        "1. Based on your observation of the temporal structure and the histogram of the residuals, do you think these errors can be modeled as independent gaussian noise?\n",
        "\n",
        "1. If you did multiple experiments, how much do the fit parameters vary between measurements? Would it surprise you more to find that $T_0$ varied or that $T_0/m$ varied?\n",
        "\n",
        "1. I would argue that the denoised amplitude has very little error. Would you agree or disagree? Why? Why can't we do a similar denoising on the period?"
      ],
      "metadata": {
        "id": "3wT-j5JgJK1g"
      }
    }
  ]
}